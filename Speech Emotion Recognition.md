# Speech_Emotion_Recognition
PURPOSE--To build a model to recognize emotion from speech using the librosa and sklearn libraries and the RAVDESS dataset.
Speech Emotion Recognition, is the act of attempting to recognize human emotion and affective states from speech.SER is tough because emotions are subjective and annotating audio is challenging.
It is project to to perform speech emotion recognition using a dataset consisting of various emotions displayed by 24 different people.

This project is done using the library 'LIBROSA'.Librosa is a Python library for analyzing audio and music. It has a flatter package layout, standardizes interfaces and names, backwards compatibility, modular functions, and readable code.
Exectuded the code using Anaconda - JUPYTER NOTEBOOK.
JupyterLab is an open-source, web-based UI for Project Jupyter and it has all basic functionalities of the Jupyter Notebook, like notebooks, terminals, text editors, file browsers, rich outputs.
we will use the libraries librosa, soundfile, and sklearn (among others) to build a model using an MLPClassifier. 


The feature extraction is done which extracts the features:
--mfcc: Mel Frequency Cepstral Coefficient, represents the short-term power spectrum of a sound
--chroma: Pertains to the 12 different pitch classes
--mel: Mel Spectrogram Frequency
